{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers torch datasets matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data and Preprocess\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load the IMDB dataset\n",
    "dataset = load_dataset(\"imdb\")\n",
    "train_data = dataset[\"train\"].shuffle(seed=42).select(range(1000))  # Use 1k samples for speed\n",
    "test_data = dataset[\"test\"].shuffle(seed=42).select(range(200))\n",
    "\n",
    "print(\"Sample review:\", train_data[0][\"text\"])\n",
    "print(\"Label (0=negative, 1=positive):\", train_data[0][\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load a Pre-Trained Model\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Load tokenizer and model\n",
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize the Data\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True, max_length=512)\n",
    "\n",
    "# Tokenize datasets\n",
    "train_data = train_data.map(tokenize, batched=True, batch_size=16)\n",
    "test_data = test_data.map(tokenize, batched=True, batch_size=16)\n",
    "\n",
    "# Format for PyTorch\n",
    "train_data.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "test_data.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the Model (Fine-Tuning)\n",
    "from transformers import Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "\n",
    "# Created a data collator that will dynamically pad the batched samples\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Training setup\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,  # Keep it short for demo purposes\n",
    "    per_device_train_batch_size=8,\n",
    "    # evaluation_strategy=\"epoch\",  # Corrected parameter name\n",
    "    logging_dir=\"./logs\",\n",
    "    # Added this to disable wandb\n",
    "    report_to=[\"none\"]  # Disable wandb and other integrations\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=test_data,\n",
    "    data_collator=data_collator,  # Added the data collator\n",
    ")\n",
    "\n",
    "# Train!\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the Model\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Evaluation results: {eval_results}\")\n",
    "\n",
    "# Create a function to analyze new customer reviews\n",
    "def analyze_sentiment(review_text):\n",
    "    inputs = tokenizer(review_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Get prediction (0 = negative, 1 = positive)\n",
    "    prediction = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    label = torch.argmax(prediction, dim=1).item()\n",
    "    score = prediction[0][label].item()\n",
    "\n",
    "    sentiment = \"positive\" if label == 1 else \"negative\"\n",
    "    return {\n",
    "        \"sentiment\": sentiment,\n",
    "        \"confidence\": score,\n",
    "        \"review\": review_text\n",
    "    }\n",
    "\n",
    "# Example usage with Jumpstart fashion retail reviews\n",
    "sample_reviews = [\n",
    "    \"I absolutely love this dress! The fabric is high quality and the fit is perfect.\",\n",
    "    \"The shirt I ordered was too small and the color was different from what was shown online.\",\n",
    "    \"Shipping was fast but the product quality was disappointing.\",\n",
    "    \"These jeans are the best I've ever owned. Will definitely buy more!\",\n",
    "    \"Customer service was unhelpful when I tried to return my order.\"\n",
    "]\n",
    "\n",
    "for review in sample_reviews:\n",
    "    result = analyze_sentiment(review)\n",
    "    print(f\"Review: {result['review'][:50]}...\")\n",
    "    print(f\"Sentiment: {result['sentiment']} (Confidence: {result['confidence']:.2f})\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sentiment distribution\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Function to analyze a batch of reviews\n",
    "def analyze_batch(reviews):\n",
    "    results = [analyze_sentiment(review) for review in reviews]\n",
    "    return results\n",
    "\n",
    "# Example: Analyze test data\n",
    "test_reviews = [example[\"text\"] for example in dataset[\"test\"].select(range(100))]\n",
    "sentiment_results = analyze_batch(test_reviews)\n",
    "\n",
    "# Count positive and negative reviews\n",
    "positive_count = sum(1 for r in sentiment_results if r[\"sentiment\"] == \"positive\")\n",
    "negative_count = sum(1 for r in sentiment_results if r[\"sentiment\"] == \"negative\")\n",
    "\n",
    "# Create visualization\n",
    "labels = ['Positive', 'Negative']\n",
    "counts = [positive_count, negative_count]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(labels, counts, color=['green', 'red'])\n",
    "plt.title('Sentiment Distribution in Customer Reviews')\n",
    "plt.ylabel('Number of Reviews')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add count labels on bars\n",
    "for i, count in enumerate(counts):\n",
    "    plt.text(i, count + 0.5, str(count), ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('sentiment_distribution.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the fine-tuned model and tokenizer\n",
    "model_save_path = \"./jumpstart_sentiment_model\"\n",
    "model.save_pretrained(model_save_path)\n",
    "tokenizer.save_pretrained(model_save_path)\n",
    "\n",
    "print(f\"Model and tokenizer saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create a directory in your Google Drive\n",
    "import os\n",
    "drive_path = \"/content/drive/My Drive/jumpstart_sentiment_model\"\n",
    "os.makedirs(drive_path, exist_ok=True)\n",
    "\n",
    "# Copy the model to Google Drive\n",
    "!cp -r ./jumpstart_sentiment_model/* \"/content/drive/My Drive/jumpstart_sentiment_model/\"\n",
    "\n",
    "print(f\"Model saved to Google Drive at: {drive_path}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
